{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kathy\\\\Desktop\\\\Python\\\\Ext_Finance_Data\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the full import out\n",
    "# Need to make the APRA date variable more dynamic\n",
    "# Then need to add visualisations\n",
    "# What is the proper way to link everything together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APRA Monthly Statistics\n",
    "\n",
    "# Household Deposits (Cash held by Australians in Banks)\n",
    "\n",
    "# https://www.apra.gov.au/monthly-authorised-deposit-taking-institution-statistics back series Mar 2019 -\n",
    "\n",
    "# Loans to households: Housing: Owner-occupied\n",
    "# Loans to households: Housing: Investment\n",
    "# Deposits by households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Name\n",
    "# Monthly authorised deposit-taking institution statistics back-series March 2019 - November 2021\n",
    "# Still need to add query to automate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "\n",
    "# Section: Libraries\n",
    "\n",
    "#############################################################\n",
    "\n",
    "import pandas as pd # Data Analysis Library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # Data Visualisation Library\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns # Data Visualisation Library\n",
    "import requests # For downloading \n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import re # Regex\n",
    "import numbers \n",
    "\n",
    "import pickle # for saving/loading files\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "\n",
    "# Section: Functions\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# pickle_save: save the files after importing and reading them\n",
    "def pickle_save(name, to_save):\n",
    "    with open('../Data/' + name + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# picle_load: load previously saved files\n",
    "def pickle_load(name):\n",
    "    with open('../Data/' + name + '.pickle', 'rb') as handle:\n",
    "        load_data = pickle.load(handle)\n",
    "    return load_data\n",
    "\n",
    "# match: search each string element within a list ('list_search') in a string ('in_string') and  \n",
    "# return the match. Used to define the type of variable within the ABS Lending Indicator datasets.\n",
    "def match(list_search, in_string):\n",
    "    # need to add restrictions on input types to list + string\n",
    "    result = [f for f in list_search if re.search(f, desclist)] \n",
    "    return(result)\n",
    "\n",
    "# human_format: format numbers to be more readable \n",
    "def human_format(num):\n",
    "    num = float('{:.3g}'.format(num))\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num /= 1000.0\n",
    "    return '{}{}'.format('{:f}'.format(num).rstrip('0').rstrip('.'), ['', 'K', 'M', 'B', 'T'][magnitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "apra_end_date = 'November 2021'\n",
    "apra_end_date_dt = datetime.strptime(apra_end_date, \"%B %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {}  \n",
    "file_dict = {\n",
    "    \n",
    "    'APRA' : {\n",
    "        'ADIs - Total' : {\n",
    "            'Metadata' : {\n",
    "                'dl_name': 'Monthly authorised deposit-taking institution statistics back-series March 2019 - November 2021',\n",
    "                'series':  ['Loans to households: Housing: Owner-occupied',\n",
    "                           'Loans to households: Housing: Investment', 'Deposits by households']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for source in file_dict:\n",
    "    if source == 'RBA':\n",
    "        for key in file_dict[source]:\n",
    "            file_dict[source][key]['Metadata']['row_drop'] = ['Description', 'Frequency', 'Type', 'Units', 'Source', \n",
    "                                                              'Publication date', 'Series ID']\n",
    "            file_dict[source][key]['Metadata']['dl_url'] = 'https://www.rba.gov.au/statistics/tables/xls/'\n",
    "            file_dict[source][key]['Metadata']['sheet_name'] = 'Data'\n",
    "            file_dict[source][key]['Metadata']['filetype'] = '.xlsx'\n",
    "            file_dict[source][key]['Metadata']['ID_row'] = 'Series ID'\n",
    "            file_dict[source][key]['Metadata']['unit_row'] = 'Units'\n",
    "            file_dict[source][key]['Metadata']['publication_row'] = 'Publication date'\n",
    "            file_dict[source][key]['Metadata']['skiprow'] = 1\n",
    "\n",
    "    elif source == 'ABS':\n",
    "        for key in file_dict[source]:\n",
    "            file_dict[source][key]['Metadata']['row_drop'] = ['Unit', 'Series Type', 'Data Type', 'Frequency', \n",
    "                                                              'Collection Month', 'No. Obs', 'Series Start', \n",
    "                                                              'Series End', 'Series ID']\n",
    "            file_dict[source][key]['Metadata']['dl_url'] = 'https://www.abs.gov.au/statistics/economy/finance/lending-indicators/latest-release/'\n",
    "            file_dict[source][key]['Metadata']['sheet_name'] = 'Data1'\n",
    "            file_dict[source][key]['Metadata']['filetype'] = '.xls'\n",
    "            file_dict[source][key]['Metadata']['ID_row'] = 'Series ID'\n",
    "            file_dict[source][key]['Metadata']['unit_row'] = 'Unit'\n",
    "            file_dict[source][key]['Metadata']['publication_row'] = 'Series End'\n",
    "            file_dict[source][key]['Metadata']['skiprow'] = 0\n",
    "            \n",
    "    elif source == 'APRA':\n",
    "        for key in file_dict[source]:\n",
    "            file_dict[source][key]['Metadata']['row_drop'] = ['NONE']\n",
    "            file_dict[source][key]['Metadata']['dl_url'] = 'https://www.apra.gov.au/sites/default/files/2022-01/' # Needs to be dynamic as well\n",
    "            file_dict[source][key]['Metadata']['sheet_name'] = 'Table 1'\n",
    "            file_dict[source][key]['Metadata']['filetype'] = '.xlsx'\n",
    "            file_dict[source][key]['Metadata']['ID_row'] = 'Manual'\n",
    "            file_dict[source][key]['Metadata']['unit_row'] = 'Manual'     # No units. Need to add one manually\n",
    "            file_dict[source][key]['Metadata']['publication_row'] = 'Manual'    # Need to add one manually\n",
    "            file_dict[source][key]['Metadata']['skiprow'] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Input/Monthly authorised deposit-taking institution statistics back-series March 2019 - November 2021.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-52fb33364bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdl_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Metadata'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dl_url'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdl_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./Input/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdl_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                   \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Input/Monthly authorised deposit-taking institution statistics back-series March 2019 - November 2021.xlsx'"
     ]
    }
   ],
   "source": [
    "# Download all the external files from the file_dict dictionary\n",
    "for source in file_dict:\n",
    "    for key in file_dict[source]:\n",
    "        dl_name = file_dict[source][key]['Metadata']['dl_name'] + file_dict[source][key]['Metadata']['filetype']\n",
    "        dl_url = file_dict[source][key]['Metadata']['dl_url'] + dl_name\n",
    "        r = requests.get(dl_url)\n",
    "        with open(\"../Input/\" + dl_name, 'wb') as f:\n",
    "                  f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to adjust the import step for APRA which is different from ABS/ RBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the below onto step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External files are imported and cleaned.Each external file is saved into the dictionary \n",
    "# ('import_file_dict') with a lookup which details the unique series ID, description and units.\n",
    "\n",
    "for source in file_dict:\n",
    "    \n",
    "    for key in file_dict[source]:   \n",
    "        \n",
    "        data_name = file_dict[source][key]['Metadata']['dl_name']\n",
    "        row_filter = file_dict[source][key]['Metadata']['row_drop']\n",
    "        series_filter = file_dict[source][key]['Metadata']['series']\n",
    "        series_name = file_dict[source][key]['Metadata']['ID_row']\n",
    "\n",
    "        read_path = './Input/' + data_name + file_dict[source][key]['Metadata']['filetype']\n",
    "        df = pd.read_excel(read_path, sheet_name = file_dict[source][key]['Metadata']['sheet_name'], \n",
    "                           skiprows = file_dict[source][key]['Metadata']['skiprow'])\n",
    "        df = df.rename(columns={ df.columns[0]: 'Title' })\n",
    "\n",
    "        description = df.columns.values\n",
    "        \n",
    "        if series_name == 'Manual':\n",
    "            series_id_row = description\n",
    "        else:\n",
    "            series_id_row = df[df['Title'] == series_name].values.tolist()[0]\n",
    "            series_id_row[0] = 'Title'\n",
    "\n",
    "        df.columns = series_id_row\n",
    "\n",
    "        # Extract Publication Date\n",
    "        \n",
    "        if file_dict[source][key]['Metadata']['publication_row'] == 'Manual':\n",
    "            pub_date = apra_end_date_dt\n",
    "        else: \n",
    "            pub_date = df.loc[df['Title'] == file_dict[source][key]['Metadata']['publication_row']].values[0,1]\n",
    "            if type(pub_date) == datetime.datetime:\n",
    "                pub_date = pub_date.strftime(\"%d-%b-%Y\")\n",
    "                \n",
    "        print(file_dict[source][key]['Metadata']['dl_name'], 'latest publication date:', pub_date) #loc = index check\n",
    "\n",
    "        # Transform Data \n",
    "        #if series_name == 'Manual':\n",
    "        #    series_id = description\n",
    "        #else:\n",
    "        #    series_id = df[df['Title'] == file_dict[source][key]['Metadata']['ID_row']].values[0]\n",
    "        \n",
    "        if source == 'APRA':\n",
    "            units = ['$ million'] * len(description)\n",
    "        else:\n",
    "            units = df[df['Title'] == file_dict[source][key]['Metadata']['unit_row']].values[0] # Unit values\n",
    "        \n",
    "        #series_lookup = pd.DataFrame(list(zip(series_id,description,units)), columns=['Series ID','Description','Unit'])\n",
    "        series_lookup = pd.DataFrame(list(zip(series_id_row,description,units)), columns=['Series ID','Description','Unit'])\n",
    "        series_lookup = series_lookup[series_lookup['Series ID'] != 'Series ID'] # Need to save these in the dictionary output\n",
    "        series_lookup = series_lookup.loc[series_lookup['Series ID'].isin(series_filter), :]\n",
    "\n",
    "        # select the series_to_filter\n",
    "        column_filter = series_lookup.loc[:,'Series ID'].values.tolist()\n",
    "        column_filter.insert(0, 'Title')\n",
    "\n",
    "        # Drop Rows\n",
    "        if source == 'APRA':\n",
    "            df_fmt = df.copy()\n",
    "        else:\n",
    "            df_fmt = df[~df['Title'].isin(row_filter)]\n",
    "            df_fmt = df_fmt.dropna(subset=['Title']) # Remove rows in first column with NA\n",
    "\n",
    "        for i in range(len(units)):\n",
    "            if(df_fmt.iloc[:,i].dtype == np.float64 or df_fmt.iloc[:,i].dtype == np.int64):\n",
    "                \n",
    "                if source == 'RBA':\n",
    "                    if units[i].strip() == \"\"\"'000\"\"\":\n",
    "                        df_fmt.iloc[:,i] = df_fmt.iloc[:,i] * 1000\n",
    "                    elif units[i].strip() == '$ million':\n",
    "                        df_fmt.iloc[:,i] = df_fmt.iloc[:,i] * 1000000\n",
    "                elif source == 'ABS':\n",
    "                    if units[i].strip() == '$ Millions':\n",
    "                        df_fmt.iloc[:,i] = df_fmt.iloc[:,i] * 1000000\n",
    "                elif source == 'APRA':\n",
    "                    if units[i].strip() == '$ million':\n",
    "                        df_fmt.iloc[:,i] = df_fmt.iloc[:,i] * 1000000\n",
    "                    \n",
    "        # Drop columns\n",
    "        df_fmt = df_fmt.loc[:,column_filter] # Keep relevant series\n",
    "\n",
    "        df_fmt = df_fmt.reset_index(drop=True)\n",
    "        df_fmt = df_fmt.rename(columns={'Title': 'Date'})\n",
    "        df_fmt = df_fmt.convert_dtypes() # Convert variable types\n",
    "        \n",
    "        file_dict[source][key]['Import_Data'] = df_fmt \n",
    "        file_dict[source][key]['Lookup'] = series_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "\n",
    "# Section: Format Tables\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# variable_dict: match terms used to define the variables\n",
    "\n",
    "variable_dict = {\n",
    "    \n",
    "    'RBA' : {\n",
    "        'measure_type' : {\n",
    "            'list' : ['number of accounts', 'total number of transactions', 'total value of transactions', \n",
    "                      'balances accruing interest', 'total balances', 'credit limits'],\n",
    "            'alias' : {\n",
    "                'number of accounts' : 'accounts',\n",
    "                'total number of transactions' : 'transactions',\n",
    "                'total value of transactions' : 'transaction value',\n",
    "                'balances accruing interest' : 'interest balance',\n",
    "                'total balances' : 'balance',\n",
    "                'credit limits' : 'limits'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'APRA' : {\n",
    "        'measure_type' : {\n",
    "            'list' : ['Loans to households: Housing: Owner-occupied', 'Loans to households: Housing: Investment', \n",
    "                      'Deposits by households'],\n",
    "            'alias' : {\n",
    "                'Loans to households: Housing: Owner-occupied' : 'Mortgages OO',\n",
    "                'Loans to households: Housing: Investment' : 'Mortgages Inv',\n",
    "                'Deposits by households' : 'Deposits'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fmt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchlist.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchlist2 = [x.lower() for x in searchlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_structure_dict: contains the variable structure for each table\n",
    "\n",
    "table_structure_dict = {}\n",
    "\n",
    "for source in file_dict:\n",
    "    table_structure_dict[source] = {}\n",
    "\n",
    "    for key in file_dict[source]:   \n",
    "        \n",
    "        table_structure_dict[source][key] = {}\n",
    "\n",
    "        lookup = file_dict[source][key]['Lookup']\n",
    "        \n",
    "        file_ref = file_dict[source][key]['Metadata']['dl_name']\n",
    "\n",
    "        for seriesloop in lookup['Series ID'].tolist():\n",
    "\n",
    "            table_structure_dict[source][key][seriesloop] = {}\n",
    "            \n",
    "            table_structure_dict[source][key][seriesloop]['file_ref'] = file_ref\n",
    "\n",
    "            if source == 'APRA':\n",
    "                desclist = lookup.loc[lookup['Series ID'] == seriesloop, 'Description'].values[0]\n",
    "            else:\n",
    "                desclist = lookup.loc[lookup['Series ID'] == seriesloop, 'Description'].values[0].lower() # why lower?\n",
    "\n",
    "            for var in variable_dict[source]:\n",
    "                \n",
    "                searchlist = variable_dict[source][var]['list']\n",
    "                \n",
    "                if match(searchlist, desclist) == []:\n",
    "                    if var == 'measure_type':\n",
    "                        output = 'total housing excluding refinancing'\n",
    "                    else:\n",
    "                        output = 'all'\n",
    "                else: \n",
    "                    output = match(searchlist, desclist)[0]\n",
    "                \n",
    "                if 'alias' in variable_dict[source][var].keys():\n",
    "                    table_structure_dict[source][key][seriesloop][var] = variable_dict[source][var]['alias'][output]\n",
    "                else:\n",
    "                    table_structure_dict[source][key][seriesloop][var] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "\n",
    "# Section: Aggregate imported tables to final state\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# Final_table_dict: contains the final aggregated dataframes that are used for visualisation/ analysis\n",
    "final_table_dict = {}\n",
    "\n",
    "for source in table_structure_dict:\n",
    "    j = 0\n",
    "    \n",
    "    final_table_dict[source] = {}\n",
    "    \n",
    "    # ABS data is combined into a master table with a single measure column\n",
    "    if source == 'ABS':  \n",
    "        \n",
    "        # Initalise empty list to store a dataframe per file\n",
    "        df_master_list = [None] * len(table_structure_dict[source])\n",
    "\n",
    "        for key in table_structure_dict[source]:\n",
    "\n",
    "            df = file_dict[source][key]['Import_Data']\n",
    "            df = df[df['Date'] >= '2019-06-01']\n",
    "            df = df.melt(id_vars=[\"Date\"])\n",
    "            \n",
    "            # Initalise empty list to store a dataframe per series\n",
    "            df_list = [None] * len(table_structure_dict[source][key]) \n",
    "            \n",
    "            i = 0\n",
    "\n",
    "            for series in table_structure_dict[source][key]:\n",
    "                \n",
    "                df_loop = df.loc[df['variable']==series,]\n",
    "                #df_loop['filename'] = final_table_dict[source][key]['Metadata']['dl_name']\n",
    "\n",
    "                for n in table_structure_dict[source][key][series]:\n",
    "                    df_loop.loc[:, n] = table_structure_dict[source][key][series][n]\n",
    "\n",
    "                    if n == 'variable':\n",
    "                        df_loop.loc[:, table_structure_dict[source][key][series][n]] = df_loop['value']\n",
    "                    else:  \n",
    "                        df_loop.loc[:, n] = table_structure_dict[source][key][series][n]\n",
    "\n",
    "                    df_loop = df_loop.rename(columns={'All':'total housing excluding refinancing'})\n",
    "                \n",
    "                df_list[i] = df_loop\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "            df_master_list[j] = pd.concat(df_list)\n",
    "\n",
    "            j = j + 1\n",
    "\n",
    "        final_table_dict[source]['Final_Data'] = pd.concat(df_master_list)\n",
    "                                              \n",
    "    # Data in RBA CC data has multiple columns\n",
    "    elif source == 'RBA':     \n",
    "        \n",
    "        for key in table_structure_dict[source]:\n",
    "            df = file_dict[source][key]['Import_Data']\n",
    "            \n",
    "            if key == 'Credit Card Data - Australia':\n",
    "                source_fmt = 'RBA-Credit'\n",
    "            elif key == 'Debit Card Data - Australia': \n",
    "                source_fmt = 'RBA-Debit'\n",
    "            \n",
    "            for series in table_structure_dict[source][key]:\n",
    "                \n",
    "                df = df.rename({series:table_structure_dict[source][key][series]['measure_type']}, axis=1)\n",
    "\n",
    "            final_table_dict[source_fmt] = {}                     \n",
    "            final_table_dict[source_fmt]['Final_Data'] = df \n",
    "            \n",
    "    elif source == 'APRA':\n",
    "        \n",
    "        for key in table_structure_dict[source]:\n",
    "            df = file_dict[source][key]['Import_Data']\n",
    "            \n",
    "            if key == 'ADIs - Total':\n",
    "                source_fmt = 'APRA-Monthly'\n",
    "            \n",
    "            for series in table_structure_dict[source][key]:\n",
    "                \n",
    "                df = df.rename({series:table_structure_dict[source][key][series]['measure_type']}, axis=1)\n",
    "\n",
    "            final_table_dict[source_fmt] = {}                     \n",
    "            final_table_dict[source_fmt]['Final_Data'] = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above is put back into zero"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
